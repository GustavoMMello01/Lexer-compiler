- Varios statements

- Além das palavras-chave "init" e do operador "=", em um código-fonte mais completo, existem vários outros tipos de tokens que geralmente precisam ser categorizados. Aqui estão alguns exemplos comuns:

- Palavras-Chave: Além de "init", muitas linguagens de programação têm palavras-chave reservadas que possuem significados específicos na sintaxe da linguagem. Exemplos incluem "if", "else", "while", "for", "return", etc.

- Identificadores: São usados para nomear variáveis, funções, classes e outros elementos do código. Eles geralmente começam com uma letra ou sublinhado, seguidos por letras, dígitos ou sublinhados.

- Números: Isso inclui números inteiros e de ponto flutuante. Além disso, alguns números podem estar em notação científica (por exemplo, 1.23e5).

- Strings: Sequências de caracteres delimitadas por aspas simples ou duplas. Dentro das strings, os caracteres têm significado literal e não são interpretados como código.

- Operadores: Além de "=", há uma variedade de operadores, como aritméticos (+, -, *, /), lógicos (&&, ||), de comparação (==, !=, >, <), entre outros.

Delimitadores: Isso inclui símbolos como parênteses (), chaves {}, colchetes [], ponto e vírgula ; e vírgula , que são usados para estruturar o código.

Comentários: Partes do código que não são executadas e servem apenas como anotações para humanos. Comentários podem ser em uma linha (// em muitas linguagens) ou em várias linhas (/* ... */).

Whitespace: Espaços em branco, tabulações e quebras de linha que são usados para formatar o código e separar tokens.

Símbolos Especiais: Outros símbolos especiais que podem ter significados específicos em uma linguagem de programação, como o ponto "." para acessar membros de uma classe.

Literais: Além de strings, há outros tipos de literais, como literais booleanos (true, false) e literais nulos (null).

Diretivas de Pré-processamento: Em linguagens como C/C++, diretivas de pré-processamento como #include e #define podem ser consideradas tokens separados.

Tipos de Dados: Nomes de tipos de dados, como "int", "float", "string", etc.

Operadores de Atribuição Especiais: Além de "=", podem haver outros operadores de atribuição como "+=", "-=", "*=", "/=", etc.

Operadores Bit a Bit: Em linguagens de baixo nível, há operadores para manipulação de bits, como "&", "|", "^", "<<", ">>".

Símbolos de Final de Instrução: Alguns idiomas não dependem apenas do ponto e vírgula, mas podem usar outros símbolos para indicar o final de uma instrução.

Estes são apenas alguns exemplos. A lista exata de tokens a serem categorizados depende da linguagem de programação que você está analisando. Cada linguagem tem suas próprias regras e padrões para tokens.


if self.token_atual.tipo == T_ID:
            id_token = self.token_atual
            self.use(T_ID)
            self.use(T_OP, "=")
            self.expr()
            print(f" {id_token.valor}")
        else:
            self.erro()



- gerar um erro lexico 
- gerar um erro sintatico
- erro lexico x erro sintatico



Vou explicar desde o começo. 
Tenho um notebook python com varias funções em diferentes blocos. 
O primeiro bloco é o onde definimos o token:
T_KEYWORD = "<keyword %s>"
T_OP = "<op %s>"
T_INT = "<int %s>"
T_STRING = "<string %s>"
T_IDENTIF = "<id %s>"
T_SPECIAL = "<special %s>"
T_PUNCT = "<punct %s>"
T_DOT = "<dot>"
T_CONDITIONAL_OP = "<conditional_op %s>"
T_COMMENT = "<comment>"

class StopExecution(Exception):
    def _render_traceback_(self):
        pass

def tokenize_line(line, line_number):
    tokens = []
    i = 0
    n = len(line)

    while i < n:
        if line[i].isspace():
            i += 1
        elif line[i] == '#':  # Comment
            tokens.append(T_COMMENT)
            break  # Skip the rest of the line
        elif line[i].isalpha():
            start = i
            while i < n and (line[i].isalnum() or line[i] == '_'):
                i += 1
            word = line[start:i]
            if word in ["var", "func", "if", "elif", "else", "return", "object", "init"]:
                tokens.append(T_KEYWORD % word)
            elif word in ["true", "false", "null", "end", "main"]:
                tokens.append(T_SPECIAL % word)
            else:
                tokens.append(T_IDENTIF % word)
        elif line[i].isdigit():
            start = i
            while i < n and line[i].isdigit():
                i += 1
            tokens.append(T_INT % line[start:i])
        elif line[i] == '"':
            start = i
            i += 1
            while i < n and line[i] != '"':
                i += 1
            if i >= n:
                print(f"Erro: String não fechada na linha {line_number}")
                raise StopExecution
            i += 1
            tokens.append(T_STRING % line[start:i])
        elif line[i] in "=<>!+-*/":
            start = i
            i += 1
            if i < n and line[i] == "=":
                i += 1
            tokens.append(T_OP % line[start:i])
        elif line[i] in "(),[]{}":
            tokens.append(T_PUNCT % line[i])
            i += 1
        elif line[i] in "?:":
            tokens.append(T_CONDITIONAL_OP % line[i])
            i += 1
        elif line[i] == '.':
            tokens.append(T_DOT)
            i += 1
        else:
            print(f"Erro: Caractere não reconhecido '{line[i]}' na linha {line_number}")
            raise StopExecution

    return tokens

def tokenize():

    try:
        token_total = [];
        with open('codigo.x', 'r') as f:
            lines = f.read().splitlines()

        line_number = 0
        for line in lines:
            line_number += 1
            tokens = tokenize_line(line, line_number)
            token_total.extend(tokens)
            #print(tokens)

        return token_total

    except StopExecution:
        print("Execução parada devido a erro.")

O segundo bloco é o analisador lexico AFD:
def analisador_lexico(filename):
    try:
        tokens_total = [];
        with open(filename, 'r') as f:
            lines = f.read().splitlines()

        line_number = 0
        for line in lines:
            line_number += 1
            tokens = tokenize_line(line, line_number)
            tokens_total.extend(tokens)
            #print(tokens)

        return tokens_total

    except StopExecution:
        print("Execução parada devido a erro.")

 O terceiro bloco é o parser que voce mexeu:
class Parser():
    def __init__(self, tokens):
        self.tokens = [Token(t.split(" ")[0], t.split(" ")[1] if len(t.split(" ")) > 1 else None) for t in tokens]
        self.pos = -1
        self.token_atual = None
        self.symbol_table = {}
        self.proximo()

    def proximo(self):
        self.pos += 1
        
        if self.pos >= len(self.tokens):
            self.token_atual = Token("EOF")
        else:    
            self.token_atual = self.tokens[self.pos]

        print(self.token_atual)
        return self.token_atual

    def erro(self):
        raise Exception('Erro de sintaxe. %s' % (self.token_atual))

    def use(self, tipo, valor=None):
        if self.token_atual.tipo != tipo:
            self.erro()
        elif valor is not None and self.token_atual.valor != valor:
            self.erro()
        else:
            self.proximo()

    def statement(self):
        if self.token_atual.tipo == "T_IDENTIF":
            self.assignment_statement()
        elif self.token_atual.tipo == "T_KEYWORD" and self.token_atual.valor in ["if", "elif", "else"]:
            self.conditional_statement()
        elif self.token_atual.tipo == "T_KEYWORD" and self.token_atual.valor in ["for", "while"]:
            self.loop_statement()
        elif self.token_atual.tipo == "T_KEYWORD" and self.token_atual.valor == "func":
            self.function_definition()
        elif self.token_atual.tipo == "T_KEYWORD" and self.token_atual.valor == "object":
            self.object_definition()
        # TODO: Adicione outros tipos de instruções conforme sua gramática

    def assignment_statement(self):
        var_name = self.token_atual.valor
        self.use("T_IDENTIF")
        self.use("T_OP", "=")
        value = self.expression()
        self.use("T_PUNCT", ";")
        self.symbol_table[var_name] = value

    def conditional_statement(self):
        if self.token_atual.valor == "if":
            self.use("T_KEYWORD", "if")
            self.use("T_PUNCT", "(")
            self.expression()  # Avalia a expressão do if, mas não faz nada com ela aqui. Normalmente, isso conduziria algum tipo de desvio condicional.
            self.use("T_PUNCT", ")")
            self.statement()
        elif self.token_atual.valor == "elif":
            self.use("T_KEYWORD", "elif")
            self.use("T_PUNCT", "(")
            self.expression()
            self.use("T_PUNCT", ")")
            self.statement()
        elif self.token_atual.valor == "else":
            self.use("T_KEYWORD", "else")
            self.statement()

    def loop_statement(self):
        if self.token_atual.valor == "for":
            self.use("T_KEYWORD", "for")
            self.use("T_PUNCT", "(")
            self.assignment_statement()  # Inicialização, ex: i = 0;
            self.expression()            # Condição, ex: i < 10;
            self.assignment_statement()  # Incremento, ex: i++;
            self.use("T_PUNCT", ")")
            self.statement()
        elif self.token_atual.valor == "while":
            self.use("T_KEYWORD", "while")
            self.use("T_PUNCT", "(")
            self.expression()            # Condição
            self.use("T_PUNCT", ")")
            self.statement()

    def function_definition(self):
        self.use("T_KEYWORD", "func")
        function_name = self

E o quarto bloco é a main que roda e chama todos os metodos:
def main():
    filename = 'codigo.x'
    print(f"Lendo o arquivo {filename}...")

    # Tokenização
    print("\nTokenização:")
    tokens = tokenize(filename)
    
    # Análise Sintática (Parser)
    print("\nAnálise Sintática:")
    parser = Parser(tokens)
    try:
        parser.start()
        print("Análise sintática concluída com sucesso!")
    except Exception as e:
        print(f"Erro no parser: {e}")

    states = {
        'tokens': tokens,
        'symbol_table': parser.symbol_table
    }
    print("\nEstados salvos:", states)


if __name__ == '__main__':
    main()

Corrija o necessario e melhore caso necesssario pensando no codigo ANT
# Bem vindo a essa nova linguagem de prog ANT
func main home(){
    2
    var a = 1
    var b=2
    var nome="Joao"

    var c = add(a,b)
    print("O resultado foi ", c)

    if(c>a){
        print(c," maior que ", a)
    }
    elif(c<b){
        print(c," menor que ", b)
    }
    else{
        print("error")
    }

    c = ternary(a,b)
    print(c)

    var mercedes = carro("mercedes", "GLE", 2022, 220)
    print("O carro polui: ", mercedes.poluicao)

    end 
}

func add(a,b){
    return a + b
}

func ternary(a,b){
    return a === b ? true : false
}

object carro(marca, modelo, ano, velocidade)
{
    init carro(marca, modelo, ano, velocidade)

    func poluicao(velocidade){
        return velocidade*10
    }
}