{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br298Ypcs989",
        "outputId": "0a318020-0995-4ea2-e350-9f46522c5562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init a\n",
            "init b\n",
            "init c\n",
            "\n",
            "a = 5\n",
            "b = 3\n",
            "c = \"12\"\n",
            "\n",
            "result = a + b\n"
          ]
        }
      ],
      "source": [
        "## lendo o código fonte\n",
        "\n",
        "arquivo = open('codigo.x','r')\n",
        "for l in arquivo.readlines():\n",
        "    l = l.replace('\\n','') # remove a quebra de linha\n",
        "    print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg6j_7gVs98_",
        "outputId": "8ae00d47-88b3-418e-d76e-1cc6e40cb094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['init', 'a']\n",
            "['init', 'b']\n",
            "['init', 'c']\n",
            "[]\n",
            "['a', '=', '5']\n",
            "['b', '=', '3']\n",
            "['c', '=', '\"12\"']\n",
            "[]\n",
            "['result', '=', 'a', '+', 'b']\n"
          ]
        }
      ],
      "source": [
        "## iniciando a definição dos tokens que serão a saída da análise léxica\n",
        "\n",
        "T_KEYWORDS_INIT = \"<keyword init>\"\n",
        "T_OP = \"<op %s>\"\n",
        "T_INT = \"<int %s>\"\n",
        "T_STRING = \"<string %s>\"\n",
        "T_IDENTIF = \"<id %s>\"\n",
        "\n",
        "arquivo = open('codigo.x','r')\n",
        "for l in arquivo.readlines():\n",
        "    l = l.replace('\\n','') # remove a quebra de linha\n",
        "    tokens = []\n",
        "    for token in l.split():\n",
        "        tokens.append(token)\n",
        "    print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWRvC4r9s99A",
        "outputId": "e38c4efd-d4c9-49a3-e9fb-5c8a48b267c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<keyword init>', None]\n",
            "['<keyword init>', None]\n",
            "['<keyword init>', None]\n",
            "[]\n",
            "[None, '<op =>', None]\n",
            "[None, '<op =>', None]\n",
            "[None, '<op =>', None]\n",
            "[]\n",
            "[None, '<op =>', None, None, None]\n"
          ]
        }
      ],
      "source": [
        "## definindo o afd principal para processar e categorizar os tokens\n",
        "\n",
        "T_KEYWORDS_INIT = \"<keyword init>\"\n",
        "T_OP = \"<op %s>\"\n",
        "T_INT = \"<int %s>\"\n",
        "T_STRING = \"<string %s>\"\n",
        "T_IDENTIF = \"<id %s>\"\n",
        "\n",
        "def afd_principal(token):\n",
        "\n",
        "    if token == \"init\":\n",
        "        return T_KEYWORDS_INIT\n",
        "    elif token == \"=\":\n",
        "        return T_OP % token\n",
        "\n",
        "    return None\n",
        "\n",
        "arquivo = open('codigo.x','r')\n",
        "for l in arquivo.readlines():\n",
        "    l = l.replace('\\n','') # remove a quebra de linha\n",
        "    tokens = []\n",
        "    for token in l.split():\n",
        "        tokens.append(afd_principal(token))\n",
        "\n",
        "    print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "nqj3qcOIs99A",
        "outputId": "7f9660d3-0630-4d57-f250-510a64629757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<keyword init>', '<id a>']\n",
            "['<keyword init>', '<id b>']\n",
            "['<keyword init>', '<id c>']\n",
            "['<keyword init>', '<id d>']\n",
            "['<keyword init>', '<id e>']\n",
            "['<keyword init>', '<id f>']\n",
            "[]\n",
            "['<id a>', '<op =>', '<id 5>']\n",
            "['<id b>', '<op =>', '<id 3>']\n",
            "num  2  -  \"12\"\n",
            "['<id c>', '<op =>', '<string \"12\">']\n",
            "num  1  -  12\"\n",
            "['<id d>', '<op =>']\n",
            "Valor inesperado na posição 4 da linha 11\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "StopExecution",
          "evalue": "ignored",
          "traceback": []
        }
      ],
      "source": [
        "## definindo uma mensagem de erro para tokens que não puderem ser processados\n",
        "\n",
        "import re\n",
        "\n",
        "T_KEYWORDS_INIT = \"<keyword init>\"\n",
        "T_OP = \"<op %s>\"\n",
        "T_INT = \"<int %s>\"\n",
        "T_STRING = \"<string %s>\"\n",
        "T_IDENTIF = \"<id %s>\"\n",
        "\n",
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass\n",
        "\n",
        "def afd_principal(token):\n",
        "\n",
        "    if token == \"init\":\n",
        "        return T_KEYWORDS_INIT\n",
        "    elif token == \"=\":\n",
        "        return T_OP % token\n",
        "    elif re.match(r\"^.+$\", token):\n",
        "        num = token.count('\"')\n",
        "        if num >= 1:\n",
        "          print(\"num \", num, \" - \", token)\n",
        "\n",
        "          # 1. indice zero começa com \"\n",
        "          # 2. um indice antes EOF (\\n)\n",
        "\n",
        "          if(token[0] == '\"'  and token[-1] == '\"'):\n",
        "            if num > 2:\n",
        "              raise ValueError('Valor inesperado')\n",
        "            return T_STRING % token\n",
        "          elif(token[0] != '\"' or token[-1] != '\"'):\n",
        "            raise ValueError('Valor inesperado')\n",
        "        return T_IDENTIF % token\n",
        "    else:\n",
        "        raise ValueError('Valor inesperado')\n",
        "    return None\n",
        "\n",
        "arquivo = open('codigo.x','r')\n",
        "ln = 1\n",
        "for l in arquivo.readlines():\n",
        "    l = l.replace('\\n','') # remove a quebra de linha\n",
        "    tokens = []\n",
        "    for token in l.split():\n",
        "        try:\n",
        "            tokens.append(afd_principal(token))\n",
        "        except Exception as e:\n",
        "            print(tokens)\n",
        "            print(str(e) + \" na posição %i da linha %i\" % (l.index(token), ln))\n",
        "            raise StopExecution\n",
        "    ln += 1\n",
        "\n",
        "    print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zolh5TCs99B"
      },
      "source": [
        "## Desafio\n",
        "\n",
        "1. Permita que o AFD reconheça strings delimitadas por aspas duplas (\"), ao mesmo tempo, não permita que a string possua outras aspas duplas (além da abertura e fechamento)\n",
        "2. Permita que o AFD reconheça identificadores (nomes de variáveis)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}