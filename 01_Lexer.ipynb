{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br298Ypcs989",
        "outputId": "0a318020-0995-4ea2-e350-9f46522c5562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init a\n",
            "init b\n",
            "init c\n",
            "\n",
            "a = 5\n",
            "b = 3\n",
            "c = \"12\"\n",
            "\n",
            "result = a + b\n"
          ]
        }
      ],
      "source": [
        "## lendo o código fonte\n",
        "\n",
        "arquivo = open('codigo.x','r')\n",
        "for l in arquivo.readlines():\n",
        "    l = l.replace('\\n','') # remove a quebra de linha\n",
        "    print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg6j_7gVs98_",
        "outputId": "8ae00d47-88b3-418e-d76e-1cc6e40cb094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['init', 'a']\n",
            "['init', 'b']\n",
            "['init', 'c']\n",
            "[]\n",
            "['a', '=', '5']\n",
            "['b', '=', '3']\n",
            "['c', '=', '\"12\"']\n",
            "[]\n",
            "['result', '=', 'a', '+', 'b']\n"
          ]
        }
      ],
      "source": [
        "## iniciando a definição dos tokens que serão a saída da análise léxica\n",
        "\n",
        "T_KEYWORDS_INIT = \"<keyword init>\"\n",
        "T_OP = \"<op %s>\"\n",
        "T_INT = \"<int %s>\"\n",
        "T_STRING = \"<string %s>\"\n",
        "T_IDENTIF = \"<id %s>\"\n",
        "\n",
        "arquivo = open('codigo.x','r')\n",
        "for l in arquivo.readlines():\n",
        "    l = l.replace('\\n','') # remove a quebra de linha\n",
        "    tokens = []\n",
        "    for token in l.split():\n",
        "        tokens.append(token)\n",
        "    print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWRvC4r9s99A",
        "outputId": "e38c4efd-d4c9-49a3-e9fb-5c8a48b267c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<keyword init>', None]\n",
            "['<keyword init>', None]\n",
            "['<keyword init>', None]\n",
            "[]\n",
            "[None, '<op =>', None]\n",
            "[None, '<op =>', None]\n",
            "[None, '<op =>', None]\n",
            "[]\n",
            "[None, '<op =>', None, None, None]\n"
          ]
        }
      ],
      "source": [
        "## definindo o afd principal para processar e categorizar os tokens\n",
        "\n",
        "T_KEYWORDS_INIT = \"<keyword init>\"\n",
        "T_OP = \"<op %s>\"\n",
        "T_INT = \"<int %s>\"\n",
        "T_STRING = \"<string %s>\"\n",
        "T_IDENTIF = \"<id %s>\"\n",
        "\n",
        "def afd_principal(token):\n",
        "\n",
        "    if token == \"init\":\n",
        "        return T_KEYWORDS_INIT\n",
        "    elif token == \"=\":\n",
        "        return T_OP % token\n",
        "\n",
        "    return None\n",
        "\n",
        "arquivo = open('codigo.x','r')\n",
        "for l in arquivo.readlines():\n",
        "    l = l.replace('\\n','') # remove a quebra de linha\n",
        "    tokens = []\n",
        "    for token in l.split():\n",
        "        tokens.append(afd_principal(token))\n",
        "\n",
        "    print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqj3qcOIs99A",
        "outputId": "4f9dd127-f223-4ac5-f18a-e072489e1970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num  2  -  \"a string\"\n",
            "['<keyword init>', '<op =>', '<id validID>', '<id _invalidStart>', '<id %invalidID>', '<id 123invalid>', '<string \"a string\">', '<id #anotherInvalid>', '<id @test>']\n"
          ]
        }
      ],
      "source": [
        "## definindo uma mensagem de erro para tokens que não puderem ser processados\n",
        "\n",
        "import re\n",
        "\n",
        "T_KEYWORDS_INIT = \"<keyword init>\"\n",
        "T_OP = \"<op %s>\"\n",
        "T_INT = \"<int %s>\"\n",
        "T_STRING = \"<string %s>\"\n",
        "T_IDENTIF = \"<id %s>\"\n",
        "\n",
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass\n",
        "\n",
        "def afd_principal(token):\n",
        "\n",
        "    # Starts only with a letter (upper or lower case), followed by letters, numbers, or underscores.\n",
        "    id_pattern = r\"^[a-zA-Z][a-zA-Z0-9_]*$\"\n",
        "\n",
        "    if token == \"init\":\n",
        "        return T_KEYWORDS_INIT\n",
        "    elif token == \"=\":\n",
        "        return T_OP % token\n",
        "    elif re.match(id_pattern, token):\n",
        "        return T_IDENTIF % token\n",
        "    elif re.match(r\"^.+$\", token):\n",
        "        num = token.count('\"')\n",
        "        if num >= 1:\n",
        "          print(\"num \", num, \" - \", token)\n",
        "\n",
        "          # 1. indice zero começa com \"\n",
        "          # 2. um indice antes EOF (\\n)\n",
        "\n",
        "          if(token[0] == '\"'  and token[-1] == '\"'):\n",
        "            if num > 2:\n",
        "              raise ValueError('Valor inesperado')\n",
        "            return T_STRING % token\n",
        "          elif(token[0] != '\"' or token[-1] != '\"'):\n",
        "            raise ValueError('Valor inesperado')\n",
        "        return T_IDENTIF % token\n",
        "    else:\n",
        "        raise ValueError('Valor inesperado')\n",
        "    return None\n",
        "\n",
        "# test_tokens_strict = [\"init\", \"=\", \"validID\", \"_invalidStart\", \"%invalidID\", \"123invalid\", '\"a string\"', \"#anotherInvalid\", \"@test\"]\n",
        "# results_strict = [afd_principal(token) for token in test_tokens_strict]\n",
        "# results_strict\n",
        "# print(results_strict)]\n",
        "\n",
        "arquivo = open('codigo.x','r')\n",
        "ln = 1\n",
        "for l in arquivo.readlines():\n",
        "    l = l.replace('\\n','') # remove a quebra de linha\n",
        "    tokens = []\n",
        "    for token in l.split():\n",
        "        try:\n",
        "            tokens.append(afd_principal(token))\n",
        "        except Exception as e:\n",
        "            print(tokens)\n",
        "            print(str(e) + \" na posição %i da linha %i\" % (l.index(token), ln))\n",
        "            raise StopExecution\n",
        "    ln += 1\n",
        "\n",
        "    print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zolh5TCs99B"
      },
      "source": [
        "## Desafio\n",
        "\n",
        "1. Permita que o AFD reconheça strings delimitadas por aspas duplas (\"), ao mesmo tempo, não permita que a string possua outras aspas duplas (além da abertura e fechamento)\n",
        "2. Permita que o AFD reconheça identificadores (nomes de variáveis)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}