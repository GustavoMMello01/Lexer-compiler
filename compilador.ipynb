{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Token</h3>\n",
    "<h4>Analisador Lexico - AFD </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_KEYWORD = \"<keyword %s>\"\n",
    "T_OP = \"<op %s>\"\n",
    "T_INT = \"<int %s>\"\n",
    "T_STRING = \"<string %s>\"\n",
    "T_IDENTIF = \"<id %s>\"\n",
    "T_SPECIAL = \"<special %s>\"\n",
    "T_PUNCT = \"<punct %s>\"\n",
    "T_DOT = \"<dot>\"\n",
    "T_CONDITIONAL_OP = \"<conditional_op %s>\"\n",
    "T_COMMENT = \"<comment>\"\n",
    "\n",
    "class Token():\n",
    "    def __init__(self, tipo, valor=None):\n",
    "        self.tipo = tipo\n",
    "        self.valor = valor\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.tipo}({self.valor})\" if self.valor else self.tipo\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "def tokenize_line(line, line_number):\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    n = len(line)\n",
    "\n",
    "    while i < n:\n",
    "        if line[i].isspace():\n",
    "            i += 1\n",
    "        elif line[i] == '#':  # Comment\n",
    "            tokens.append(Token(\"T_COMMENT\"))\n",
    "            break \n",
    "        elif line[i].isalpha():\n",
    "            start = i\n",
    "            while i < n and (line[i].isalnum() or line[i] == '_'):\n",
    "                i += 1\n",
    "            word = line[start:i]\n",
    "            if word in [\"var\", \"func\", \"if\", \"elif\", \"else\", \"return\", \"object\", \"init\"]:\n",
    "                tokens.append(Token(\"T_KEYWORD\", word))\n",
    "            elif word in [\"true\", \"false\", \"null\", \"end\", \"main\"]:\n",
    "                tokens.append(Token(\"T_SPECIAL\", word))\n",
    "            else:\n",
    "                tokens.append(Token(\"T_IDENTIF\", word))\n",
    "        elif line[i].isdigit():\n",
    "            start = i\n",
    "            while i < n and line[i].isdigit():\n",
    "                i += 1\n",
    "            tokens.append(Token(\"T_INT\", line[start:i]))\n",
    "        elif line[i] == '\"':\n",
    "            start = i\n",
    "            i += 1\n",
    "            while i < n and line[i] != '\"':\n",
    "                i += 1\n",
    "            if i >= n:\n",
    "                print(f\"Erro: String não fechada na linha {line_number}\")\n",
    "                raise StopExecution\n",
    "            i += 1\n",
    "            tokens.append(Token(\"T_STRING\", line[start:i]))\n",
    "        elif line[i] in \"=<>!+-*/\":\n",
    "            start = i\n",
    "            i += 1\n",
    "            if i < n and line[i] == \"=\":\n",
    "                i += 1\n",
    "            tokens.append(Token(\"T_OP\", line[start:i]))\n",
    "        elif line[i] in \"(),[]{}\":\n",
    "            tokens.append(Token(\"T_PUNCT\", line[i]))\n",
    "            i += 1\n",
    "        elif line[i] in \"?:\":\n",
    "            tokens.append(Token(\"T_CONDITIONAL_OP\", line[i]))\n",
    "            i += 1\n",
    "        elif line[i] == '.':\n",
    "            tokens.append(Token(\"T_DOT\"))\n",
    "            i += 1\n",
    "        else:\n",
    "            print(f\"Erro: Caractere não reconhecido '{line[i]}' na linha {line_number}\")\n",
    "            raise StopExecution\n",
    "    return tokens\n",
    "\n",
    "def tokenize():\n",
    "\n",
    "    try:\n",
    "        token_total = [];\n",
    "        with open('codigo.x', 'r') as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "        line_number = 0\n",
    "        for line in lines:\n",
    "            line_number += 1\n",
    "            tokens = tokenize_line(line, line_number)\n",
    "            token_total.extend(tokens)\n",
    "            #print(tokens)\n",
    "\n",
    "        return token_total\n",
    "\n",
    "    except StopExecution:\n",
    "        print(\"Execução parada devido a erro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Analisador Sinatico - Parser </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = tokens\n",
    "        self.current_idx = 0  \n",
    "        self.current_token = self.tokens[0] if tokens else None\n",
    "        self.symbol_table = {}\n",
    "\n",
    "    def get_next_token(self):\n",
    "        self.current_idx += 1\n",
    "        if self.current_idx < len(self.tokens):\n",
    "            self.current_token = self.tokens[self.current_idx]\n",
    "        else:\n",
    "            self.current_token = None\n",
    "\n",
    "    def eat(self, token_type):\n",
    "        if self.current_token.tipo == token_type:\n",
    "            self.get_next_token()\n",
    "        else:\n",
    "            raise Exception(f\"Erro de sintaxe. Esperado: {token_type}. Recebido: {self.current_token.tipo}\")\n",
    "\n",
    "    def factor(self):\n",
    "        \"\"\"factor : INT | IDENTIF | ( expr )\"\"\"\n",
    "        token = self.current_token\n",
    "        if token.tipo == 'T_INT':\n",
    "            self.eat('T_INT')\n",
    "            return int(token.valor)\n",
    "        elif token.tipo == 'T_IDENTIF':\n",
    "            self.eat('T_IDENTIF')\n",
    "            return self.symbol_table.get(token.valor, None) \n",
    "        elif token.tipo == 'T_PUNCT' and token.valor == '(':\n",
    "            self.eat('T_PUNCT')\n",
    "            result = self.expr()\n",
    "            self.eat('T_PUNCT')\n",
    "            return result\n",
    "\n",
    "    def term(self):\n",
    "        \"\"\"term : factor ((MUL | DIV) factor)*\"\"\"\n",
    "        result = self.factor()\n",
    "\n",
    "        while self.current_token is not None and self.current_token.tipo in ('T_OP') and self.current_token.valor in ['*', '/']:\n",
    "            token = self.current_token\n",
    "            if token.valor == '*':\n",
    "                self.eat('T_OP')\n",
    "                result *= self.factor()\n",
    "            elif token.valor == '/':\n",
    "                self.eat('T_OP')\n",
    "                result /= self.factor()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def expr(self):\n",
    "        \"\"\"expr : term ((PLUS | MINUS) term)*\"\"\"\n",
    "        result = self.term()\n",
    "\n",
    "        while self.current_token is not None and self.current_token.tipo in ('T_OP') and self.current_token.valor in ['+', '-']:\n",
    "            token = self.current_token\n",
    "            if token.valor == '+':\n",
    "                self.eat('T_OP')\n",
    "                result += self.term()\n",
    "            elif token.valor == '-':\n",
    "                self.eat('T_OP')\n",
    "                result -= self.term()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def assignment(self):\n",
    "        \"\"\"IDENTIF EQUALS expr\"\"\"\n",
    "        var_name = self.current_token.valor\n",
    "        self.eat('T_IDENTIF')\n",
    "        self.eat('T_OP')\n",
    "        var_value = self.expr()\n",
    "        self.symbol_table[var_name] = var_value\n",
    "    \n",
    "    def conditional_statement(self):\n",
    "        \"\"\" if/elif/else statement \"\"\"\n",
    "        self.eat('T_KEYWORD')  # Consumir o \"if\" ou \"elif\"\n",
    "        condition = self.expr()  # Avaliar a expressão condicional\n",
    "\n",
    "        if condition:\n",
    "            self.eat('T_PUNCT')  # Consumir o '{'\n",
    "            self.start()  # Processar o bloco de código dentro do if/elif\n",
    "            self.eat('T_PUNCT')  # Consumir o '}'\n",
    "        else:\n",
    "            # pular o bloco de código e possivelmente ir para um \"elif\" ou \"else\"\n",
    "            while self.current_token.tipo != 'T_PUNCT' or self.current_token.valor != '}':\n",
    "                self.eat(self.current_token.tipo)\n",
    "\n",
    "            self.eat('T_PUNCT')  # Consumir o '}'\n",
    "\n",
    "            if self.current_token and self.current_token.valor == \"elif\":\n",
    "                self.conditional_statement()\n",
    "            elif self.current_token and self.current_token.valor == \"else\":\n",
    "                self.eat('T_KEYWORD')  # Consumir o \"else\"\n",
    "                self.eat('T_PUNCT')  # Consumir o '{'\n",
    "                self.start()  # Processar o bloco de código dentro do else\n",
    "                self.eat('T_PUNCT')  # Consumir o '}'\n",
    "\n",
    "    def loop_statement(self):\n",
    "        \"\"\" while statement\"\"\"\n",
    "        \"\"\"TODO Implementar outros loops como o for...\"\"\"\n",
    "        self.eat('T_KEYWORD')  # Consumir o \"while\"\n",
    "        condition = self.expr()  # Avaliar a expressão condicional\n",
    "\n",
    "        while condition:\n",
    "            self.eat('T_PUNCT')  # Consumir o '{'\n",
    "            self.start()  # Processar o bloco de código dentro do loop\n",
    "            self.eat('T_PUNCT')  # Consumir o '}'\n",
    "\n",
    "    def function_definition(self):\n",
    "        \"\"\" func IDENTIFIER (...) \"\"\"\n",
    "        self.eat('T_KEYWORD')  # Consumir o \"func\"\n",
    "        func_name = self.current_token.valor\n",
    "        self.eat('T_IDENTIF')\n",
    "        self.eat('T_PUNCT')  # Consumir o '('\n",
    "\n",
    "        # Lista de parâmetros (opcional)\n",
    "        parameters = []\n",
    "        while self.current_token.tipo != 'T_PUNCT' or self.current_token.valor != ')':\n",
    "            parameters.append(self.current_token.valor)\n",
    "            self.eat('T_IDENTIF')\n",
    "\n",
    "            # Se houver uma vírgula, é porque há mais parâmetros\n",
    "            if self.current_token.valor == ',':\n",
    "                self.eat('T_PUNCT')  # Consumir a ','\n",
    "\n",
    "        self.eat('T_PUNCT')  # Consumir o ')'\n",
    "\n",
    "        # Adicionar função à tabela de símbolos (para este exemplo, vamos apenas armazenar o nome)\n",
    "        self.symbol_table[func_name] = {'type': 'function', 'parameters': parameters}\n",
    "\n",
    "        self.eat('T_PUNCT')  # Consumir o '{'\n",
    "        self.start()  # Processar o corpo da função\n",
    "        self.eat('T_PUNCT')  # Consumir o '}'\n",
    "\n",
    "    def object_definition(self):\n",
    "        \"\"\" object IDENTIFIER \"\"\"\n",
    "        \"\"\"TODO expandir isso para incluir membros de objeto, métodos, etc.\"\"\"\n",
    "        self.eat('T_KEYWORD')  # Consumir o \"object\"\n",
    "        object_name = self.current_token.valor\n",
    "        self.eat('T_IDENTIF')\n",
    "\n",
    "        self.symbol_table[object_name] = {'type': 'object'}\n",
    "\n",
    "    def print_command(self):\n",
    "        \"\"\" Trata o comando print \"\"\"\n",
    "        self.eat('T_KEYWORD')  # Consumir \"print\"\n",
    "        self.eat('T_PUNCT')    # Consumir '('\n",
    "        \n",
    "        # Aqui podemos melhorar para tratar expressões mais complexas dentro do print.\n",
    "        while self.current_token.tipo != 'T_PUNCT' or self.current_token.valor != ')':\n",
    "            if self.current_token.tipo == 'T_STRING':\n",
    "                # Supondo que esteja imprimindo uma string, podemos apenas consumir o token.\n",
    "                self.eat('T_STRING')\n",
    "            else:\n",
    "                self.expr()\n",
    "\n",
    "            if self.current_token.valor == ',':\n",
    "                self.eat('T_PUNCT')  # Consumir ','\n",
    "\n",
    "        self.eat('T_PUNCT')    # Consumir ')'\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\" point of entry for our parser \"\"\"\n",
    "        while self.current_token is not None:\n",
    "            if self.current_token.tipo == 'T_IDENTIF':\n",
    "                self.assignment()\n",
    "            elif self.current_token.tipo == 'T_KEYWORD':\n",
    "                if self.current_token.valor == \"if\":\n",
    "                    self.conditional_statement()\n",
    "                elif self.current_token.valor == \"print\":\n",
    "                    self.print_command()\n",
    "                elif self.current_token.valor == \"while\":\n",
    "                    self.loop_statement()\n",
    "                elif self.current_token.valor == \"func\":\n",
    "                    self.function_definition()\n",
    "                elif self.current_token.valor == \"object\":\n",
    "                    self.object_definition()\n",
    "            else:\n",
    "                self.expr()\n",
    "\n",
    "        if self.current_token is not None:\n",
    "            raise Exception('Syntax error: unexpected token {}'.format(self.current_token))\n",
    "\n",
    "        return self.symbol_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Compilador</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo o arquivo codigo2.x ...\n",
      "\n",
      "Tokenização:\n",
      "Tokens: [<__main__.Token object at 0x00000180F536A810>, <__main__.Token object at 0x00000180F536B890>, <__main__.Token object at 0x00000180F536AB10>, <__main__.Token object at 0x00000180F53688D0>, <__main__.Token object at 0x00000180F5368490>, <__main__.Token object at 0x00000180F5368690>, <__main__.Token object at 0x00000180F536A050>, <__main__.Token object at 0x00000180F5369810>, <__main__.Token object at 0x00000180F5368890>, <__main__.Token object at 0x00000180F536B710>, <__main__.Token object at 0x00000180F5369050>, <__main__.Token object at 0x00000180F5369110>, <__main__.Token object at 0x00000180F536A6D0>, <__main__.Token object at 0x00000180F5368350>, <__main__.Token object at 0x00000180F53680D0>, <__main__.Token object at 0x00000180F5369B90>, <__main__.Token object at 0x00000180F53697D0>, <__main__.Token object at 0x00000180F536B010>, <__main__.Token object at 0x00000180F536B310>, <__main__.Token object at 0x00000180F5369C10>, <__main__.Token object at 0x00000180F536AED0>, <__main__.Token object at 0x00000180F536AD50>, <__main__.Token object at 0x00000180F5368E50>, <__main__.Token object at 0x00000180F5369590>, <__main__.Token object at 0x00000180F536B910>, <__main__.Token object at 0x00000180F5368ED0>, <__main__.Token object at 0x00000180F5368A10>, <__main__.Token object at 0x00000180F5369E10>, <__main__.Token object at 0x00000180F536A190>, <__main__.Token object at 0x00000180F5368050>, <__main__.Token object at 0x00000180F536B510>, <__main__.Token object at 0x00000180F5369490>, <__main__.Token object at 0x00000180F5369CD0>, <__main__.Token object at 0x00000180F5368190>, <__main__.Token object at 0x00000180F5369950>, <__main__.Token object at 0x00000180F53687D0>, <__main__.Token object at 0x00000180F5369E50>, <__main__.Token object at 0x00000180F536BE90>, <__main__.Token object at 0x00000180F536A210>, <__main__.Token object at 0x00000180F536AA90>, <__main__.Token object at 0x00000180F5369F90>, <__main__.Token object at 0x00000180F5368550>, <__main__.Token object at 0x00000180F536B350>, <__main__.Token object at 0x00000180F536B3D0>, <__main__.Token object at 0x00000180F5369D50>, <__main__.Token object at 0x00000180F536AD90>, <__main__.Token object at 0x00000180F536AA50>, <__main__.Token object at 0x00000180F536AC10>, <__main__.Token object at 0x00000180F5369550>, <__main__.Token object at 0x00000180F53684D0>, <__main__.Token object at 0x00000180F5368290>, <__main__.Token object at 0x00000180F5368590>, <__main__.Token object at 0x00000180F536AF10>, <__main__.Token object at 0x00000180F536A250>, <__main__.Token object at 0x00000180F5369B10>, <__main__.Token object at 0x00000180F5369BD0>, <__main__.Token object at 0x00000180F536AF90>, <__main__.Token object at 0x00000180F5369C90>, <__main__.Token object at 0x00000180F536B650>, <__main__.Token object at 0x00000180F536AC50>, <__main__.Token object at 0x00000180F536A850>, <__main__.Token object at 0x00000180F536A290>, <__main__.Token object at 0x00000180F536BDD0>, <__main__.Token object at 0x00000180F5368A50>, <__main__.Token object at 0x00000180F2E58410>, <__main__.Token object at 0x00000180F4D64150>, <__main__.Token object at 0x00000180F536B090>, <__main__.Token object at 0x00000180F4D67D50>, <__main__.Token object at 0x00000180F4D64E50>, <__main__.Token object at 0x00000180F4D64ED0>, <__main__.Token object at 0x00000180F4D64290>, <__main__.Token object at 0x00000180F4D64590>, <__main__.Token object at 0x00000180F4D66950>, <__main__.Token object at 0x00000180F4D66190>, <__main__.Token object at 0x00000180F4D65150>, <__main__.Token object at 0x00000180F4D67ED0>, <__main__.Token object at 0x00000180F4D66F90>, <__main__.Token object at 0x00000180F4D66BD0>, <__main__.Token object at 0x00000180F4D641D0>, <__main__.Token object at 0x00000180F4D64190>, <__main__.Token object at 0x00000180F4D64210>, <__main__.Token object at 0x00000180F4D66990>, <__main__.Token object at 0x00000180F5425F50>, <__main__.Token object at 0x00000180F5425F90>, <__main__.Token object at 0x00000180F54260D0>, <__main__.Token object at 0x00000180F5425790>, <__main__.Token object at 0x00000180F5425D50>, <__main__.Token object at 0x00000180F5426E10>, <__main__.Token object at 0x00000180F54254D0>, <__main__.Token object at 0x00000180F5425150>, <__main__.Token object at 0x00000180F5426D50>, <__main__.Token object at 0x00000180F5424490>, <__main__.Token object at 0x00000180F54240D0>, <__main__.Token object at 0x00000180F5426DD0>, <__main__.Token object at 0x00000180F5424890>, <__main__.Token object at 0x00000180F5425D10>, <__main__.Token object at 0x00000180F5426310>, <__main__.Token object at 0x00000180F5425750>, <__main__.Token object at 0x00000180F5427850>, <__main__.Token object at 0x00000180F54241D0>, <__main__.Token object at 0x00000180F5426790>, <__main__.Token object at 0x00000180F54273D0>, <__main__.Token object at 0x00000180F5424E10>, <__main__.Token object at 0x00000180F5426D10>, <__main__.Token object at 0x00000180F5426E90>, <__main__.Token object at 0x00000180F5427590>, <__main__.Token object at 0x00000180F5424710>, <__main__.Token object at 0x00000180F5426910>, <__main__.Token object at 0x00000180F5425810>, <__main__.Token object at 0x00000180F5425350>, <__main__.Token object at 0x00000180F5427890>, <__main__.Token object at 0x00000180F5427990>, <__main__.Token object at 0x00000180F5427610>, <__main__.Token object at 0x00000180F5426C90>, <__main__.Token object at 0x00000180F5425C10>, <__main__.Token object at 0x00000180F5425E50>, <__main__.Token object at 0x00000180F5426590>, <__main__.Token object at 0x00000180F5424050>, <__main__.Token object at 0x00000180F52E2F90>, <__main__.Token object at 0x00000180F52E0D10>, <__main__.Token object at 0x00000180F52E1A10>, <__main__.Token object at 0x00000180F5425950>, <__main__.Token object at 0x00000180F52E1010>, <__main__.Token object at 0x00000180F53F7490>, <__main__.Token object at 0x00000180F537C210>, <__main__.Token object at 0x00000180F537C990>, <__main__.Token object at 0x00000180F537CDD0>, <__main__.Token object at 0x00000180F537F3D0>, <__main__.Token object at 0x00000180F537FED0>, <__main__.Token object at 0x00000180F537C590>, <__main__.Token object at 0x00000180F537C710>, <__main__.Token object at 0x00000180F537C150>, <__main__.Token object at 0x00000180F537C2D0>, <__main__.Token object at 0x00000180F537F110>, <__main__.Token object at 0x00000180F537C950>, <__main__.Token object at 0x00000180F537F450>, <__main__.Token object at 0x00000180F537C0D0>, <__main__.Token object at 0x00000180F537EAD0>, <__main__.Token object at 0x00000180F537FF50>, <__main__.Token object at 0x00000180F537F190>, <__main__.Token object at 0x00000180F537CB90>, <__main__.Token object at 0x00000180F537CD10>, <__main__.Token object at 0x00000180F537F490>, <__main__.Token object at 0x00000180F537D290>, <__main__.Token object at 0x00000180F537D0D0>, <__main__.Token object at 0x00000180F537C250>, <__main__.Token object at 0x00000180F537C750>, <__main__.Token object at 0x00000180F537CAD0>, <__main__.Token object at 0x00000180F537CA90>, <__main__.Token object at 0x00000180F4917450>, <__main__.Token object at 0x00000180F53675D0>, <__main__.Token object at 0x00000180F5367710>, <__main__.Token object at 0x00000180F5364D10>, <__main__.Token object at 0x00000180F5365D50>, <__main__.Token object at 0x00000180F5366810>, <__main__.Token object at 0x00000180F5364890>, <__main__.Token object at 0x00000180F5364810>, <__main__.Token object at 0x00000180F5365F10>, <__main__.Token object at 0x00000180F5367DD0>, <__main__.Token object at 0x00000180F49E1E10>, <__main__.Token object at 0x00000180F3479DD0>, <__main__.Token object at 0x00000180F34787D0>, <__main__.Token object at 0x00000180F3479F90>, <__main__.Token object at 0x00000180F4D94E10>, <__main__.Token object at 0x00000180F4D97190>, <__main__.Token object at 0x00000180F4D960D0>, <__main__.Token object at 0x00000180F4D95450>, <__main__.Token object at 0x00000180F4D95DD0>, <__main__.Token object at 0x00000180F4D97450>, <__main__.Token object at 0x00000180F4D94A50>, <__main__.Token object at 0x00000180F52BFC10>, <__main__.Token object at 0x00000180F52BF650>, <__main__.Token object at 0x00000180F52BF610>, <__main__.Token object at 0x00000180F4D97B50>, <__main__.Token object at 0x00000180F52BF590>]\n",
      "\n",
      "Análise Sintática:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gusta\\Desktop\\Lexer-compiler\\compilador.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEstados salvos:\u001b[39m\u001b[39m\"\u001b[39m, states)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\Users\\gusta\\Desktop\\Lexer-compiler\\compilador.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m parser \u001b[39m=\u001b[39m Parser(tokens)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     parser\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAnálise sintática concluída com sucesso!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;32mc:\\Users\\gusta\\Desktop\\Lexer-compiler\\compilador.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobject_definition()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpr()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSyntax error: unexpected token \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token))\n",
      "\u001b[1;32mc:\\Users\\gusta\\Desktop\\Lexer-compiler\\compilador.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexpr\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"expr : term ((PLUS | MINUS) term)*\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mterm()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token\u001b[39m.\u001b[39mtipo \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mT_OP\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token\u001b[39m.\u001b[39mvalor \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m         token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token\n",
      "\u001b[1;32mc:\\Users\\gusta\\Desktop\\Lexer-compiler\\compilador.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mterm\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"term : factor ((MUL | DIV) factor)*\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfactor()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token\u001b[39m.\u001b[39mtipo \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mT_OP\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token\u001b[39m.\u001b[39mvalor \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token\n",
      "\u001b[1;32mc:\\Users\\gusta\\Desktop\\Lexer-compiler\\compilador.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mErro de sintaxe. Esperado: \u001b[39m\u001b[39m{\u001b[39;00mtoken_type\u001b[39m}\u001b[39;00m\u001b[39m. Recebido: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token\u001b[39m.\u001b[39mtipo\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfactor\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"factor : INT | IDENTIF | ( expr )\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/Desktop/Lexer-compiler/compilador.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_token\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filename = 'codigo2.x'\n",
    "    print(f\"Lendo o arquivo {filename} ...\")\n",
    "\n",
    "    # Tokenização\n",
    "    print(\"\\nTokenização:\")\n",
    "    tokens = tokenize()\n",
    "    print(\"Tokens:\", tokens)    \n",
    "    \n",
    "    # Análise Sintática (Parser)\n",
    "    print(\"\\nAnálise Sintática:\")\n",
    "    parser = Parser(tokens)\n",
    "    try:\n",
    "        parser.start()\n",
    "        print(\"Análise sintática concluída com sucesso!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no parser: {e}\")\n",
    "\n",
    "    states = {\n",
    "        'tokens': tokens,\n",
    "        'symbol_table': parser.symbol_table\n",
    "    }\n",
    "    print(\"\\nEstados salvos:\", states)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
